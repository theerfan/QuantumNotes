From: https://www.youtube.com/watch?v=SygLi2hqRHQ&t=4248s

## Question
Can we have an alternative representation of the state $\ket{\psi}$ such that we can have an efficient classical simulation of quantum circuits? (Remember that the overhead of this simulation scales with $2^n$ where $n$ is the number of qubits.)

## Answer
Yes, sometimes; using the two methods of:
1. Tensor networks
2. Stabilizer framework

In this lecture, we will focus on the second method.
The stabilizer framework also has applications in the field of quantum error correction, and it will result in the Gotteman-Knill theorem.

---

## The stabilizer formalism

### Intuition

#### Attempt 1: Expanding the density matrix in the Pauli basis

Every Hermitian matrix that acts on the $2 \times 2$ vectors (this includes density operators) can be expanded in the Pauli basis
$$\rho = \sum_{i=1}^4 \lambda_i \sigma_i$$
Where $\sigma_i$ are the Pauli matrices and $\lambda_i \in \mathbb{R}$ are the coefficients.

- Example #1:
    $$|0\rangle \langle 0| = \frac{1}{2} (I + \sigma_z)$$ 
    Thinking of this in the eigendecomposition form, we have $I = |0\rangle \langle 0 | + |1\rangle \langle 1 |$ and $\sigma_z = |0\rangle \langle 0 | - |1\rangle \langle 1 |$.

- Example #2:
    Any density matrix $\rho$ can be written as:
    $$ \rho = \frac{1}{2} (I + r_x \sigma_x + r_y \sigma_y + r_z \sigma_z)$$
    The coefficient of $I$ is $1$ because we need the trace to be $1$ and the only non-traceless matrix in this sum is $I$. \
    Also, the vector $\vec{r} = (r_x, r_y, r_z)$ is called the Bloch vector whose norm is the purity of the state. $||\vec{r}||_{2} \leq 1$.

For higher dimensions, our basis is going to be generalized to the following:

$$
P_n := \{ \otimes_{i=1}^{n} \sigma_i \, | \, \sigma_i \in Pauli \}
$$

Generally, $|P_n| = 4^ n$ elements!

(Why is this a basis? Because using the Hilbert-Schdmit product $\braket{A, B} = Tr(A^{\dagger} B)$, these matrices are orthogonal to each other and they span the entire space.)
(As for the Hilbert-Schdmit product, it is a generalization of the dot product to matrices, and you can easily see it as it gives the same inner product for vectors.)

So this attempt failed at overcoming the exponential overhead of the simulation, so let's try something else!

---

#### Attempt 2: Casting "shadows" of Pauli elements
(This has nothing to do with classical shadows and shadow tomography.)

In attempt 1, we used many ($4^n$) bits to represent a single state. \
Now, Let's try to use few bits to represent many states. [I'm already smelling group theory lol] \
[Spoiler: this won't work still but will set the stage for attempt 3 which will work.]

Consider the operator $ZZZ = Z \otimes Z \otimes Z$, which has $2$ eigenspaces $E_1$ (with eigenvalue $1$) and $E_{-1}$ (with eigenvalue $-1$). \

Writing this out more explicitly, we see that

$$
E_1 = \{ \ket{\psi} | ZZZ \ket{\psi} = \ket{\psi} \}
$$
(We say $ZZZ$ __stabilizes__ $\ket{\psi}$.)

Thinking about this, we will see that exactly half of the eigenstates of $ZZZ$ are in $E_1$ and the other half are in $E_{-1}$.

Generally, \
The operator $Z^{\otimes n}$ has $2^n$ eigenspaces $E_{1}$ and $E_{-1}$, each of which has the dimension $2^{n-1}$.

In other words,

$$
E_{1} (Z^{\otimes n}) = span \{ \ket{x_1 \dots x_n} \, | \text{ Hamming weight}(\ket{x_1 \dots x_n}) = \text{even} \}
$$

Conclusion: If we're only using Pauli matrices to specify an operator, we'll only need $O(n)$ bits to do so, and we can represent, via $E_1(Z^{\otimes n})$, $2^{n-1}$ quantum states.

(The $E_1$ of our operator is in some sense the "shadow" of the operator.)

This is too general and we need to cut that space down to be more specific about the states we want to represent.

---

#### Attempt 3: Cutting down the shadows via set intersection

The general idea is to use __two__ operators $A$ and $B$ to represent a single state $\ket{\psi}$, which means we'll need to use $2 \times O(n)$ bits to represent $\ket{\psi}$ and we hope that the intersection of the shadows of $A$ and $B$ will be small enough to mean something.

For example, now consider the operators $ZZ$ and $XX$. \
Knowing that $X = HZH$, we write:

$$
\begin{align*}
E_{1} (ZZ) &= span \{ \ket{x_1 x_2} \, | \text{ Hamming weight}(\ket{x_1 x_2}) = \text{even} \} \\
&= span (|00\rangle, |11\rangle) \\
\, \\
E_{1} (XX) &= span \{ H_1 \otimes H_2 \ket{x_1 x_2} \, | \text{ Hamming weight}(\ket{x_1 x_2}) = \text{even} \} \\
&= span (|++\rangle, |--\rangle)
\end{align*}
$$

And we see that:

$$
E_{1}(XX) \cap E_1(ZZ) = span (|00\rangle + |11\rangle) 
$$

This is the bell state! \
So what I've got here is that intead of writing down the entire state $\ket{\psi}$, I can write down $ZZ$ and $XX$ write down the bell state as the intersection of their $E_1$'s.

---

The question that naturally comes up here is that how can we find __meaningful__ intersections of these shadows? \
[The answer is coming, hold tight!]

---

A __crucial__ point here is that this "trick" works because $[XX, ZZ] = 0$, which means they're simultaneously diagonalizable, meaning we want the joint eigenspaces of these Pauli Strings.


Writing our results in the bell-state basis to see it more clearly:

$$
XX = +1 \times |\phi^{+}\rangle \langle \phi^{+}| -1 \times |\phi^{-}\rangle \langle \phi^{-}| +1 \times |\psi^{+}\rangle \langle \psi^{+}| -1 \times |\psi^{-}\rangle \langle \psi^{-}| \\
\, \\
ZZ = +1 \times |\phi^{+}\rangle \langle \phi^{+}| +1 \times |\phi^{-}\rangle \langle \phi^{-}| -1 \times |\psi^{+}\rangle \langle \psi^{+}| -1 \times |\psi^{-}\rangle \langle \psi^{-}|
$$

We see that the only element which gives both of them the same $+1$ eigenvalue is $|\phi^{+}\rangle \langle \phi^{+}|$.

So the big idea is to write down Pauli strings that all pairwise commute with each other, and then we can use the intersection of their shadows to represent a state.

Why would we want to do this? \
1. Quantum Error Correction (QEC) \
2. Gottesman-Knill Theorem

---

## Gottseman-Knill Theorem

Quantum circuits consisting of the following form can be classically efficiently simulated:

1. The starting state is $\ket{0}^{\otimes n}$.
2. We're only allowed to apply the following gates: $H, X, Y, Z, S, CNOT$.
3. We're going to measure the state in the computational basis. i.e. the observable is $Z^{\otimes n}$.

Of course conditions $1$ and $3$ can be easily removed by adding more pauli gates to the start and the beginning of the circuit. (Our circuit is going to be part of a larger circuit.)

We can also do intermediate measurements which is made possible by the principle of deferred measurement.

The gates that we're __NOT ALLOWED__ to use are $T = \sqrt{S} = \begin{pmatrix}1 & 0 \\ 0 & e^{i\frac{\pi}{4}} \end{pmatrix}$ and $CCNOT$.

---

## Formalizing the stabilizer formalism

An $n$-bit __Pauli string__ is any operator of the form $P = \otimes_{i=1}^n \sigma_i$ where $\sigma_i \in \{I, X, Y, Z\}$.

### The Pauli Group

Recall these properties of the Pauli operators:

For $\sigma_i, \sigma_j \in {X, Y, Z}$, such that $i \neq j$, we have:

1. $\sigma_i^2 = I$
2. $\sigma_i \sigma_j = - \sigma_j \sigma_i$ \
   i.e. $\{\sigma_i, \sigma_j\} = 0$, meaning they anti-commute.
3. $\sigma_i \sigma_j \propto \sigma_k$ where $k \neq i, j$. \
   Meaning that Pauli strings are closed under multiplication.

Precisely, up to $\{ \pm 1, \pm i \}$, the product of any $2$ Pauli strings is a Pauli string.

Also, $\forall$ Pauli string $g$, $\exists$ a unique inverse pauli string $g^{-1}$ such that $g g^{-1} = I^{\otimes n}$.  [see the group structure?]

In conclusion, the **Pauli Group** is defined as:

$$
G_n := \{ c \otimes^{n}_{i=1} \sigma_i \, | \, \sigma_i \in \{I, X, Y, Z\}, \, c \in \{ \pm 1, \pm i \} \}  
$$

is a group under multiplication.

For any $S \subseteq G_n$, $\braket{S} \subseteq G_n$ is the subgroup generated by $S$. 
($S$ could be a subset and not just one element.)

<br/>

---

## Joint $1$-eigenspaces of Pauli strings

Goal: Pick a generating set $S \subseteq G_n$ such that $E_1(S) \neq \empty$. \
i.e. $dim(E_1(S)) > 0$.

Theorem: For a fixed $S \subseteq G_n$, we have $\forall \ket{\psi}, \, \ket{\psi} \in E_1(S) \iff \ket{\psi} \in E_1(\braket{S})$.

__We say that $S$ is a stabilizer of $E_1(S)$.__

Another goal we have is to NOT pick a generating set whose intersection is zero. \
e.g. if $-I   \in \braket{S} \implies E_1(S) = \empty$.

Also, e.g. if $S = \{XX, YY, ZZ \}$, since $XX \cdot YY \cdot ZZ = (iI) \otimes (iI) = -I$, we have $E_1(S) = \empty$. 

---
<br/>

## How to pick a generating set $S \subseteq G_n$?

Let $S \subseteq G_n$. Then, $E_1(S) \neq \empty$ iff:
1. For any $A, B \in S, \quad [A, B] = 0$,
2. $-I \notin \braket{S}$.

### Why is condition $1$ _necessary_? 
Because with regards to the Pauli strings, for any $A, B \in S$, if $[A, B] \neq 0$, then $\{A, B \} = 0$, meaning they anti-commute, which makes the intersection of their shadows empty.

### Why are these conditions _sufficient_?

Lemma (of Stabilizer dimension): \
For any $k$ where $1 \leq k \leq n$, let $S = \{g_1, \dots, g_k \} \subseteq G_n$ be the set of _independent_ generators satisfying our $2$ conditions, then:
$$
dim(E_1(S)) = 2^{n-k}
$$

Therefore if you want a unique state in your $|E_1(S)$, you need to have $k=n$ independent generators. 

### (Sketch of) Proof for lemma:

Goal: Given $S \subseteq G_n$, we want to write down $w^k$ projectors $\Pi_i$ onto orthogonal subspaces of _equal_ dimension, such that $\Pi_i$ still projects onto $E_1(S)$.

Step 1: Projectors onto $E_1(S)$. \
e.g. $S = \{XX, ZZ \}$, we can write the following projectors:

$$
\Pi_{\pm XX} = \frac{I \pm XX}{2} \\
\, \\
\Pi_{\pm ZZ} = \frac{I \pm ZZ}{2}
$$

__Question__: So what is the projector on $E_1(XX) \cap E_1(ZZ)$?

Naive guess: $\Pi_{XX} \Pi_{ZZ}$.

Note that this is not true in general! \
For any $\Pi_A, \Pi_B$, the projector $\Pi_A \Pi_B$ does not necessarily project onto $E_1(A) \cap E_1(B)$. \
This only works because of our pairwise commutativity assumption!

__Question__: How to get $3$ other projectors onto orthogonal spaces?

We can write all $4$ possible combinations!

$$
\Pi_{XX} \Pi_{ZZ}, \quad \Pi_{XX} \Pi_{-ZZ}, \quad \Pi_{-XX} \Pi_{ZZ}, \quad \Pi_{-XX} \Pi_{-ZZ}
$$

(We can check to see that the product of any two of these projectors is $0$, therefore they're orthogonal.)

To fully prove our lemma, we have to prove that the subspaces we get are:
1. Non-empty
2. Of equal dimension

To prove the first point, we can write the following:

$$
\Pi_{XX} \Pi_{ZZ} + \Pi_{XX} \Pi_{-ZZ} + \Pi_{-XX} \Pi_{ZZ} + \Pi_{-XX} \Pi_{-ZZ} = II
$$

So there must be something in these projectors that projects to a non-zero subspace. (Sounds like a bit of a weak proof but we move.)

And for the second point, we use the following Linear Algebra theorem which states:

> Conjugation by a unitary operator preserves the dimension (rank) of a subspace.

In other words:

$\forall$ unitary $U$ and normal operator $A$, $rank(A) = rank(UAU^{\dagger})$.

So we just need to find a unitary that moves us from one of the projectors to another (finding a chain basically) to prove that they all have the same dimension.

Such unitaries exist and for example, $U = X_1 \otimes I_2$ takes us from $\Pi_{XX} \Pi_{ZZ}$ to $\Pi_{XX} \Pi_{-ZZ}$. \
(We can easily check this by computation, and this can be generalized to higher dimensions with the same idea.)

(All have the same size, so the intersection with each of them shrinks the dimension by a factor of $2$.)

---

## Proof of Gottesman-Knill theorem

Remember that the 3 conditions we had for the Gottesman-Knill theorem were:

> 1. The starting state is $\ket{0}^{\otimes n}$.
> 2. We're only allowed to apply the following gates: $H, X, Y, Z, S, CNOT$.
> 3. We're going to measure the state in the computational basis. i.e. the observable is $Z^{\otimes n}$.

We need to find stabilizers for all the states that we're going to have in this.

1. For the starting state, $\ket{0}^n$, we choose the following:
    $$
    S = \{Z_1, Z_2, \dots, Z_n \}
    $$

    (In each of these, the identity $I$ operator gets applied to all the other qubits.)

2. For gate simulation, we know that in the statevector representation, we say that 
   $$
   \begin{align*}
   \ket{\psi} &\stackrel{U}{\rightarrow} U \ket{\psi} \\
   \, \\
   S &\stackrel{U}{\rightarrow} U S U^{\dagger} \\ 
   &:= \{UgU^{\dagger} \mid g \in S \}
   \end{align*}
   $$

   How did we get that? \
   We see that for any $g \in S$, $\ket{\psi} \in E_1(S)$ (every $g \in S$ stabilizes $\ket{\psi}$), meaning that we can write:

   $$
   \begin{align*}
   U \ket{\psi} 
   &= U (g \ket{\psi}) \\
   &= U g (U^{\dagger} U) \ket{\psi} \\
   &= (UgU^{\dagger}) U \ket{\psi} 
   \end{align*}
   $$

Now, we have a fear that these $U$ operators might transform our Pauli subgroups into non-Pauli ones.

And this is __Precisely__ what we avoided when we restricted our $U$'s to the ones we picked in the Gotteman-Knill theorem, and we call them \
__The Clifford Group__:
$$
\begin{align*}
C_G :&= \braket{H, X, Y, Z, S, CNOT} \\
&= \{U \, | \, \forall g \in G_n \, ; \, U g U^{\dagger} \in G_n \}
\end{align*}
$$

Which is the set of unitaries that map Pauli strings to Pauli strings!

__Question__: So how do clifford gates change stabilizer generators?

$$
\begin{align*}
HXH^{\dagger} &= Z \\
HZH^{\dagger} &= X \\
SXS^{\dagger} &= Y \\
SZS^{\dagger} &= S \\
\end{align*}
$$

And,

$$
\begin{align*}
CNOT_{1 \rightarrow 2} (X_1 \otimes I) CNOT_{1 \rightarrow 2}^{\dagger} &= X_1 X_2 \\
CNOT_{1 \rightarrow 2} (I \otimes X_2) CNOT_{1 \rightarrow 2}^{\dagger} &= I X_2 \\ 
CNOT_{1 \rightarrow 2} (Z_1 \otimes I) CNOT_{1 \rightarrow 2}^{\dagger} &= Z_1 I \\
CNOT_{1 \rightarrow 2} (I \otimes Z_2) CNOT_{1 \rightarrow 2}^{\dagger} &= Z_1 Z_2 \\
\end{align*}
$$

And don't forget about:

3. Measurements!
   
   Suppose that $\ket{\psi}$ has been stabilized by $S = \braket{S_1, \dots, S_n}$.

   Goal: We want to measure observable $Z^{\otimes n}$. \
   This observable has two projectors $\Pi_{+} = \frac{I + Z^{\otimes n}}{2}$ and $\Pi_{-} = \frac{I - Z^{\otimes n}}{2}$.

   Imagine we want to know $\braket{\psi | \Pi_{+} | \psi}$. (The other projector is symmetric.) 

   This gives rise to $2$ cases which we'll handle separately:

   > Case 1. When for all $i \in [n]$, it is such that $[Z^{\otimes n}, g_i] = 0$. \
   This is the easy case, and we claim that $\pm Z^{\otimes n} \in \braket{g_1, \dots, g_n}$ (either one of them).

   This claim will give rise to the fact that either
   $$
   \braket{\psi | Z^{\otimes n} | \psi} = \braket{\psi | \psi} = 1
   $$
    Which means we'll always see $1$ as the output.
   Or,
   $$
   \braket{\psi | Z^{\otimes n} | \psi} = \braket{\psi | - (-Z^{\otimes n}) | \psi} = -1
   $$
   Which means we'll always see $-1$ as the output.
   (Because $Z^{\otimes n}$ is the stabilizer, it will give the same state out when applied to $\ket{\psi}$)

   > Case 2. When for some $i \in [n]$, it is such that $\{Z^{\otimes n}, g_i\} = 0$. \
   (We need to assume that it commutes with all other generators but that comes without a loss of generality.) \
   Claim: $\braket{\psi | \Pi_{+} | \psi} = \braket{\psi | \Pi_{-} | \psi} = \frac{1}{2}$.

   Let's see that in action:

   $$
    \begin{align*}
    \braket{\psi | \Pi_{+} | \psi} 
    &= \braket{\psi | (\frac{I + Z^{\otimes n}}{2}) | \psi} \\
    &= \braket{\psi | (\frac{I + Z^{\otimes n}}{2}) g_i | \psi} \\
    &\stackrel{AC}{=} \braket{\psi | g_i (\frac{I - Z^{\otimes n}}{2}) | \psi} \\
    &= (\braket{\psi | g_i^{\dagger} ) \frac{I - Z^{\otimes n}}{2} | \psi} \\
    &= \braket{\psi | \frac{I - Z^{\otimes n}}{2} | \psi} \\
    &= \frac{1}{2} \braket{\psi | \Pi_{-} | \psi}
    \end{align*}
   $$

   The second to last line comes from the fact that the $g_i$'s are always Hermitian! \
   (For if they weren't, we would have the $-I$ in our generated subgroup which would screw up the entire $+1$ eigenspace thing.)

All of this means that at the end of our stabilizer computation, we'll either get a definite answer (Case 1) of $\pm 1$ or a fair coin flip 50/50 chance of getting either $\pm 1$. (Case 2).

__Question__: What is the post-measurement state?

- Case 1: We get a definite answer, which means that either \
  $Z^{\otimes n} \in \braket{g_1, \dots, g_n}$ or $-Z^{\otimes n} \in \braket{S}$. \
  Which means that the stabilizer remains unchanged.
  
- Case 2: We know that $\{ Z^{\otimes n} , g_i \} = 0$ and $[Z^{\otimes n}, g_j] = 0$ for $j \neq i$. \
  Since it has only two options, we do a "post-selection" by conditioning on the outcome we get. (Either $+1$ or $-1$) 

  If we get $+1$, our stabilizer becomes:
  $$
  \braket{g_1, \dots, g_{i-1}, Z^{\otimes n},  g_{i+1}, \dots, g_n}
  $$

  And if we get $-1$, our stabilizer becomes:
  $$
  \braket{g_1, \dots, g_{i-1}, -Z^{\otimes n},  g_{i+1}, \dots, g_n}
  $$

  (Only that one generator changes and the state collapses to the $+1$ or $-1$ eigenspace of $Z^{\otimes n}$ and you update your stabilizer to always be in the positive eigenspace.)
